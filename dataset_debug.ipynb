{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug for Scientific data\n",
    "[PeerRead](https://github.com/allenai/PeerRead) (accept/reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_peer_read(tokenize=True, \n",
    "                   lower=True, \n",
    "                   shuffle=True, \n",
    "                   random_state=42):\n",
    "    \"\"\"\n",
    "    Details here\n",
    "    \"\"\"\n",
    "    \n",
    "    import json\n",
    "    \n",
    "    def get_parsed(path, data_mode, label_mode):\n",
    "        \"\"\"\n",
    "        get the file names\n",
    "        \"\"\"\n",
    "        parsed_data = {}\n",
    "        parsed_label = {}\n",
    "\n",
    "        for key,item in data_mode.items():\n",
    "            parsed_data[key] = glob.glob1(os.path.join(path, item),\n",
    "                                         '*')\n",
    "        \n",
    "        for key,item in label_mode.items():\n",
    "            parsed_label[key] = glob.glob1(os.path.join(path, item),\n",
    "                                          '*')\n",
    "            \n",
    "        meta = [(key, len(item)) for key,item in parsed_data.items()]\n",
    "\n",
    "        return meta, parsed_data, parsed_label\n",
    "    \n",
    "    def get_data(meta, data, label, data_mode, label_mode, mode=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        # Args\n",
    "            mode: {'train', 'test', 'dev'}\n",
    "        # returns\n",
    "            x, y\n",
    "        \n",
    "        \"\"\"\n",
    "        if mode is not None:\n",
    "            x = []\n",
    "            y = []\n",
    "            for k in data.keys():\n",
    "                for i in range(len(data[k][mode])):\n",
    "                    with open(os.path.join(path[k], data_mode[mode], data[k][mode][i])) as json_file:  \n",
    "                        file = json.load(json_file) \n",
    "                        if file['metadata']['sections'] is not None:\n",
    "                            temp = ' '\n",
    "                            for key in file['metadata']['sections']:\n",
    "                                if key['heading'] is not None:\n",
    "                                    temp = ' '.join([temp, '{} {}'.format(key['heading'], key['text'].strip())])\n",
    "                    x.append(temp.replace('\\n', ' '))\n",
    "                    \n",
    "                    # TODO : check if both filename are the same\n",
    "                    with open(os.path.join(path[k], label_mode[mode], label[k][mode][i])) as json_file:  \n",
    "                        file = json.load(json_file) \n",
    "                        print(file['reviews'])\n",
    "                        y.append(file['accepted'])\n",
    "                    \n",
    "            return x, y\n",
    "        else:\n",
    "            raise ValueError('mode doesn\\'t exists')\n",
    "            \n",
    "    path = {}\n",
    "    path['acl'] = './dataset/PeerRead/data/acl_2017'\n",
    "    path['iclr'] = './dataset/PeerRead/data/iclr_2017'\n",
    "    path['coNLL'] = './dataset/PeerRead/data/conll_2016'\n",
    "    path['ai'] = './dataset/PeerRead/data/arxiv.cs.ai_2007-2017'\n",
    "    path['cl'] = './dataset/PeerRead/data/arxiv.cs.cl_2007-2017'\n",
    "    path['lg'] = './dataset/PeerRead/data/arxiv.cs.lg_2007-2017'\n",
    "    data_mode = {'train' : 'train/parsed_pdfs/',\n",
    "             'test' : 'test/parsed_pdfs/',\n",
    "             'dev' : 'dev/parsed_pdfs/'}\n",
    "    label_mode = {'train' : 'train/reviews/',\n",
    "             'test' : 'test/reviews/',\n",
    "             'dev' : 'dev/reviews/'}\n",
    "\n",
    "    meta, data, label = {}, {}, {}\n",
    "    meta['acl'], data['acl'], label['acl'] = get_parsed(path['acl'], data_mode, label_mode)\n",
    "    meta['iclr'], data['iclr'], label['iclr'] = get_parsed(path['iclr'], data_mode, label_mode)\n",
    "    meta['coNLL'], data['coNLL'], label['coNLL'] = get_parsed(path['coNLL'], data_mode, label_mode)\n",
    "    meta['ai'], data['ai'], label['ai'] = get_parsed(path['ai'], data_mode, label_mode)\n",
    "    meta['cl'], data['cl'], label['cl'] = get_parsed(path['cl'], data_mode, label_mode)\n",
    "    meta['lg'], data['lg'], label['lg'] = get_parsed(path['lg'], data_mode, label_mode)\n",
    "    \n",
    "    X_train_corpus, y_train = get_data(meta, data, label, data_mode, label_mode, 'train')\n",
    "    X_test_corpus, y_test = get_data(meta, data, label, data_mode, label_mode, 'test')\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(y_train))       \n",
    "        \n",
    "        X_train_corpus = [X_train_corpus[i] for i in indices]\n",
    "        y_train = y_train[indices]\n",
    "        \n",
    "        indices = np.random.permutation(len(y_test))\n",
    "        \n",
    "        X_test_corpus = [X_test_corpus[i] for i in indices]\n",
    "        y_test = y_test[indices]\n",
    "        logging.info('Shuffled.')\n",
    "    \n",
    "    if lower:\n",
    "        X_train_corpus = [text.lower() for text in X_train_corpus]\n",
    "        X_test_corpus = [text.lower() for text in X_test_corpus]\n",
    "        logging.info('Lowered.')\n",
    "        \n",
    "    if tokenize:\n",
    "        X_train_corpus = [word_tokenize(text) for text in X_train_corpus]\n",
    "        X_test_corpus = [word_tokenize(text) for text in X_test_corpus]\n",
    "        logging.info('Tokenized.')\n",
    "    \n",
    "    return X_train_corpus, X_test_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'IMPACT': '3', 'SUBSTANCE': '4', 'APPROPRIATENESS': '5', 'MEANINGFUL_COMPARISON': '3', 'PRESENTATION_FORMAT': 'Poster', 'comments': '- Strengths:\\n\\nThe paper addresses a long standing problem concerning automatic evaluation of\\nthe output of generation/translation systems.\\n\\nThe analysis of all the available metrics is thorough and comprehensive.\\n\\nThe authors demonstrate a new metric with a higher correlation with human\\njudgements\\n\\nThe bibliography will help new entrants into the field.\\n\\n- Weaknesses:\\n\\nThe paper is written as a numerical analysis paper, with very little insights\\nto linguistic issues in generation, the method of generation, the differences\\nin the output from a different systems and human generated reference.\\n\\nIt is unclear if the crowd source generated references serve well in the\\ncontext of an application that needs language generation.\\n\\n- General Discussion:\\n\\nOverall, the paper could use some linguistic examples (and a description of the\\ndifferent systems) at the risk of dropping a few tables to help the reader with\\nintuitions.', 'SOUNDNESS_CORRECTNESS': '5', 'ORIGINALITY': '5', 'is_meta_review': None, 'RECOMMENDATION': '3', 'CLARITY': '4', 'REVIEWER_CONFIDENCE': '3'}]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accepted'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-d03e7e516279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_peer_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-220-a7fef57ded95>\u001b[0m in \u001b[0;36mload_peer_read\u001b[0;34m(tokenize, lower, shuffle, random_state)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mX_train_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mX_test_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-220-a7fef57ded95>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(meta, data, label, data_mode, label_mode, mode)\u001b[0m\n\u001b[1;32m     54\u001b[0m                         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accepted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accepted'"
     ]
    }
   ],
   "source": [
    "x_train, x_test = load_peer_read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 637)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys(['reviews', 'abstract', 'histories', 'id', 'title']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
